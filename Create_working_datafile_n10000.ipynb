{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "143425dd",
   "metadata": {},
   "source": [
    "# Synthea self-harm classification project: Creating the working datafile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce6e2b3",
   "metadata": {},
   "source": [
    "## **See the README file for information on generating the initial datafiles**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27361be5",
   "metadata": {},
   "source": [
    "The code below is used to merge the initial datafiles into one working datafile (final_data_modified.csv). Specific variables likely to contain information relevant to identifying suicide-related visits were retained in the merged datafile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aa9c429-a651-49a0-98c6-b55b37df749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load the first data file\n",
    "data_file1 = '/Users/SarahA/synthea/output/csv/encounters.csv'\n",
    "df1 = pd.read_csv(data_file1, low_memory = False)\n",
    "\n",
    "# Define the specific variables (columns) to keep\n",
    "desired_columns = ['Id', 'PATIENT', 'CODE', 'DESCRIPTION', 'REASONCODE', 'REASONDESCRIPTION', 'ENCOUNTERCLASS']\n",
    "\n",
    "# Filter the dataframe to retain only the desired columns\n",
    "df1 = df1[desired_columns]\n",
    "\n",
    "# Load the second data file\n",
    "data_file2 = '/Users/SarahA/synthea/output/csv/patients.csv'\n",
    "df2 = pd.read_csv(data_file2, low_memory = False)\n",
    "\n",
    "# Define the specific variables (columns) to keep\n",
    "desired_columns = ['Id', 'BIRTHDATE', 'RACE', 'ETHNICITY', 'GENDER', 'INCOME']\n",
    "\n",
    "# Filter the dataframe to retain only the desired columns\n",
    "df2 = df2[desired_columns]\n",
    "\n",
    "# Load the third data file\n",
    "data_file3 = '/Users/SarahA/synthea/output/csv/claims.csv'\n",
    "df3 = pd.read_csv(data_file3)\n",
    "\n",
    "# Define the specific variables (columns) to keep\n",
    "desired_columns = ['Id', 'PATIENTID', 'DIAGNOSIS1', 'DIAGNOSIS2', 'DIAGNOSIS3', 'DIAGNOSIS4', 'DIAGNOSIS5', 'DIAGNOSIS6', 'DIAGNOSIS7', 'DIAGNOSIS8']\n",
    "\n",
    "# Filter the dataframe to retain only the desired columns\n",
    "df3 = df3[desired_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da803bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'PATIENT', 'CODE', 'DESCRIPTION', 'REASONCODE',\n",
      "       'REASONDESCRIPTION', 'ENCOUNTERCLASS'],\n",
      "      dtype='object')\n",
      "Index(['Id', 'BIRTHDATE', 'RACE', 'ETHNICITY', 'GENDER', 'INCOME'], dtype='object')\n",
      "Index(['Id', 'PATIENTID', 'DIAGNOSIS1', 'DIAGNOSIS2', 'DIAGNOSIS3',\n",
      "       'DIAGNOSIS4', 'DIAGNOSIS5', 'DIAGNOSIS6', 'DIAGNOSIS7', 'DIAGNOSIS8'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df1.columns)\n",
    "print(df2.columns)\n",
    "print(df3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba512b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the first two dataframes\n",
    "merged_df = df1.merge(df2, left_on='PATIENT', right_on='Id', how='left')\n",
    "\n",
    "# Rename the 'PATIENTID' column in the third dataframe to match the merged dataframe\n",
    "df3 = df3.rename(columns={'PATIENTID': 'PATIENT'})\n",
    "\n",
    "# Merge the third dataframe based on the columns from the first merge\n",
    "merged_df = merged_df.merge(df3, left_on='PATIENT', right_on='PATIENT', how='left')\n",
    "\n",
    "merged_df.to_csv('merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3af95f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dw/9kv692xj65d8csvjp0w67g740000gp/T/ipykernel_51516/1185204573.py:6: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Id_x                               PATIENT  \\\n",
      "0  5f87dd8b-f3f5-f5ff-b602-629ff78f9dd2  c546d63c-62e1-1322-3628-a9646839e090   \n",
      "1  5f87dd8b-f3f5-f5ff-b602-629ff78f9dd2  c546d63c-62e1-1322-3628-a9646839e090   \n",
      "2  5f87dd8b-f3f5-f5ff-b602-629ff78f9dd2  c546d63c-62e1-1322-3628-a9646839e090   \n",
      "3  5f87dd8b-f3f5-f5ff-b602-629ff78f9dd2  c546d63c-62e1-1322-3628-a9646839e090   \n",
      "4  5f87dd8b-f3f5-f5ff-b602-629ff78f9dd2  c546d63c-62e1-1322-3628-a9646839e090   \n",
      "\n",
      "        CODE                                 DESCRIPTION  REASONCODE  \\\n",
      "0  162673000  General examination of patient (procedure)         NaN   \n",
      "1  162673000  General examination of patient (procedure)         NaN   \n",
      "2  162673000  General examination of patient (procedure)         NaN   \n",
      "3  162673000  General examination of patient (procedure)         NaN   \n",
      "4  162673000  General examination of patient (procedure)         NaN   \n",
      "\n",
      "  REASONDESCRIPTION ENCOUNTERCLASS                                  Id_y  \\\n",
      "0               NaN       wellness  c546d63c-62e1-1322-3628-a9646839e090   \n",
      "1               NaN       wellness  c546d63c-62e1-1322-3628-a9646839e090   \n",
      "2               NaN       wellness  c546d63c-62e1-1322-3628-a9646839e090   \n",
      "3               NaN       wellness  c546d63c-62e1-1322-3628-a9646839e090   \n",
      "4               NaN       wellness  c546d63c-62e1-1322-3628-a9646839e090   \n",
      "\n",
      "    BIRTHDATE   RACE  ...  INCOME                                    Id  \\\n",
      "0  1992-12-30  black  ...  158170  27eb36d6-1b8a-c831-573c-aba2f74de509   \n",
      "1  1992-12-30  black  ...  158170  9a9bcba0-7234-cebe-c97b-2baff9967671   \n",
      "2  1992-12-30  black  ...  158170  9b5769f9-1c44-03a1-2a5f-905e424db492   \n",
      "3  1992-12-30  black  ...  158170  1cebefcb-af1e-b323-3a49-c84d33b5dd72   \n",
      "4  1992-12-30  black  ...  158170  6991d56a-2129-915b-0692-a3ce408d9a0c   \n",
      "\n",
      "   DIAGNOSIS1 DIAGNOSIS2  DIAGNOSIS3  DIAGNOSIS4  DIAGNOSIS5  DIAGNOSIS6  \\\n",
      "0   162673000        NaN         NaN         NaN         NaN         NaN   \n",
      "1   162673000        NaN         NaN         NaN         NaN         NaN   \n",
      "2   162673000        NaN         NaN         NaN         NaN         NaN   \n",
      "3    33879002        NaN         NaN         NaN         NaN         NaN   \n",
      "4    33879002        NaN         NaN         NaN         NaN         NaN   \n",
      "\n",
      "   DIAGNOSIS7  DIAGNOSIS8  \n",
      "0         NaN         NaN  \n",
      "1         NaN         NaN  \n",
      "2         NaN         NaN  \n",
      "3         NaN         NaN  \n",
      "4         NaN         NaN  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '/Users/SarahA/synthea/merged_data.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc896b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Dataframe Shape: (10000, 26)\n"
     ]
    }
   ],
   "source": [
    "# Create a subset of cases with non-empty \"REASONDESCRIPTION\"\n",
    "subset_with_reason = df[df['REASONDESCRIPTION'].notna()]\n",
    "\n",
    "# Get all cases with \"REASONDESCRIPTION\" data\n",
    "cases_with_reason = subset_with_reason.sample(n=372, random_state=42)\n",
    "\n",
    "# Calculate the number of additional cases needed\n",
    "additional_cases_needed = 10000 - len(cases_with_reason)\n",
    "\n",
    "# Create a random sample of additional cases from the remaining data\n",
    "additional_cases = df.drop(cases_with_reason.index).sample(n=additional_cases_needed, random_state=42)\n",
    "\n",
    "# Concatenate the two subsets to get the final 10,000 cases\n",
    "final_df = pd.concat([cases_with_reason, additional_cases])\n",
    "\n",
    "print(\"Final Dataframe Shape:\", final_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf9edb5",
   "metadata": {},
   "source": [
    "### Identify the outcome of interest (in this case, suicide-related events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e6cd37-0fd7-43cc-9502-3c3559743bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REASONDESCRIPTION\n",
      "Suicidal deliberate poisoning      227\n",
      "Attempted suicide - cut/stab        75\n",
      "Attempted suicide - suffocation     66\n",
      "Suicide - suffocation                3\n",
      "Suicide - firearms                   1\n",
      "Name: count, dtype: int64\n",
      "327     1\n",
      "33      1\n",
      "15      1\n",
      "314     1\n",
      "57      1\n",
      "       ..\n",
      "6106    0\n",
      "5563    0\n",
      "5762    0\n",
      "1232    0\n",
      "7642    0\n",
      "Name: SuicideRelatedEvent, Length: 10000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = final_df\n",
    "#Examine the outcome of interest\n",
    "print(df['REASONDESCRIPTION'].value_counts())\n",
    "\n",
    "# Define keywords related to suicide\n",
    "suicide_keywords = ['suicide', 'self-harm', 'suicidal']\n",
    "\n",
    "# Create a binary variable 'SuicideRelatedEvent'\n",
    "df['SuicideRelatedEvent'] = df['REASONDESCRIPTION'].str.lower().str.contains('|'.join(suicide_keywords))\n",
    "\n",
    "# Fill NaN values with 0 (assuming 0 indicates events that are not related to suicide)\n",
    "df['SuicideRelatedEvent'] = df['SuicideRelatedEvent'].fillna(0).astype(int)\n",
    "\n",
    "# Print the 'SuicideRelatedEvent' column\n",
    "print(df['SuicideRelatedEvent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1caeb5e",
   "metadata": {},
   "source": [
    "### Examine missing data within the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be3742d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per feature:\n",
      "REASONCODE            9628\n",
      "REASONDESCRIPTION     9628\n",
      "DIAGNOSIS2            9971\n",
      "DIAGNOSIS3           10000\n",
      "DIAGNOSIS4           10000\n",
      "DIAGNOSIS5           10000\n",
      "DIAGNOSIS6           10000\n",
      "DIAGNOSIS7           10000\n",
      "DIAGNOSIS8           10000\n",
      "dtype: int64\n",
      "\n",
      "Percentage of missing values per feature:\n",
      "REASONCODE            96.28\n",
      "REASONDESCRIPTION     96.28\n",
      "DIAGNOSIS2            99.71\n",
      "DIAGNOSIS3           100.00\n",
      "DIAGNOSIS4           100.00\n",
      "DIAGNOSIS5           100.00\n",
      "DIAGNOSIS6           100.00\n",
      "DIAGNOSIS7           100.00\n",
      "DIAGNOSIS8           100.00\n",
      "dtype: float64\n",
      "\n",
      "Overall percentage of missing values in the entire dataframe: 34.31807692307692\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check missing values in all features\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Filter features with missing values\n",
    "features_with_missing = missing_values[missing_values > 0]\n",
    "\n",
    "# Print missing values per feature\n",
    "print(\"Missing values per feature:\")\n",
    "print(features_with_missing)\n",
    "\n",
    "# Calculate the percentage of missing values per feature\n",
    "percentage_missing = (features_with_missing / len(df)) * 100\n",
    "\n",
    "# Print the percentage of missing values per feature\n",
    "print(\"\\nPercentage of missing values per feature:\")\n",
    "print(percentage_missing)\n",
    "\n",
    "# Check overall percentage of missing values in the entire dataframe\n",
    "overall_percentage_missing = (df.isnull().sum().sum() / np.product(df.shape)) * 100\n",
    "print(\"\\nOverall percentage of missing values in the entire dataframe:\", overall_percentage_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b911398d",
   "metadata": {},
   "source": [
    "### Identify diagnosis codes within the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f997572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Diagnosis Codes in DIAGNOSIS1:\n",
      "[410620009 162673000 287185009  33879002 287182007  86849004 287193009]\n",
      "\n",
      "Diagnosis Code Distribution in DIAGNOSIS1:\n",
      "DIAGNOSIS1\n",
      "162673000    4703\n",
      "410620009    3950\n",
      "33879002     1280\n",
      "86849004       43\n",
      "287185009      14\n",
      "287182007       9\n",
      "287193009       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n",
      "Unique Diagnosis Codes in DIAGNOSIS2:\n",
      "[           nan 2.87185009e+08 2.87182007e+08 8.68490040e+07]\n",
      "\n",
      "Diagnosis Code Distribution in DIAGNOSIS2:\n",
      "DIAGNOSIS2\n",
      "86849004.0     19\n",
      "287185009.0     7\n",
      "287182007.0     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diagnosis_columns = ['DIAGNOSIS1', 'DIAGNOSIS2']\n",
    "\n",
    "for column in diagnosis_columns:\n",
    "    # Check unique values in the current diagnosis column\n",
    "    unique_diagnosis_codes = final_df[column].unique()\n",
    "\n",
    "    # Print the unique diagnosis codes for the current column\n",
    "    print(f\"Unique Diagnosis Codes in {column}:\")\n",
    "    print(unique_diagnosis_codes)\n",
    "\n",
    "    # Analyze the distribution of diagnosis codes for the current column\n",
    "    diagnosis_code_distribution = final_df[column].value_counts()\n",
    "    print(f\"\\nDiagnosis Code Distribution in {column}:\")\n",
    "    print(diagnosis_code_distribution)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7351ccad",
   "metadata": {},
   "source": [
    "### Create income range and age variable from existing data. Save the modified data to a new file (final_data_modified.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ef97b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Income Ranges:\n",
      "['25k-50k', '150k+', '0-25k', '75k-100k', '100k-150k', '50k-75k']\n",
      "Categories (6, object): ['0-25k' < '25k-50k' < '50k-75k' < '75k-100k' < '100k-150k' < '150k+']\n",
      "\n",
      "Income Range Distribution:\n",
      "INCOME_RANGE\n",
      "0-25k        1882\n",
      "25k-50k      1861\n",
      "100k-150k    1692\n",
      "150k+        1646\n",
      "50k-75k      1605\n",
      "75k-100k     1314\n",
      "Name: count, dtype: int64\n",
      "          BIRTHDATE  Age\n",
      "30981861 2001-09-25   22\n",
      "58777479 1939-04-03   84\n",
      "41337713 1967-08-21   56\n",
      "16070944 1956-02-18   67\n",
      "72935481 1974-03-23   49\n",
      "...             ...  ...\n",
      "22106434 1965-02-17   58\n",
      "877023   1964-10-03   59\n",
      "85859185 1967-03-09   56\n",
      "22733173 1981-10-22   42\n",
      "66156749 2016-08-22    7\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Assuming 'INCOME_RESPONSE' is the column related to income\n",
    "income_column = 'INCOME'\n",
    "\n",
    "# Define income bins\n",
    "income_bins = [0, 25000, 50000, 75000, 100000, 150000, float('inf')] \n",
    "\n",
    "# Define corresponding labels for the bins\n",
    "income_labels = ['0-25k', '25k-50k', '50k-75k', '75k-100k', '100k-150k', '150k+']\n",
    "\n",
    "# Create a new column 'INCOME_RANGE' with the income ranges\n",
    "df['INCOME_RANGE'] = pd.cut(df[income_column], bins=income_bins, labels=income_labels, include_lowest=True)\n",
    "\n",
    "# Display the unique income ranges and their distribution\n",
    "unique_income_ranges = df['INCOME_RANGE'].unique()\n",
    "income_range_distribution = df['INCOME_RANGE'].value_counts()\n",
    "\n",
    "print(\"Unique Income Ranges:\")\n",
    "print(unique_income_ranges)\n",
    "\n",
    "print(\"\\nIncome Range Distribution:\")\n",
    "print(income_range_distribution)\n",
    "\n",
    "df['BIRTHDATE'] = pd.to_datetime(df['BIRTHDATE'])\n",
    "\n",
    "# Calculate age based on the current date\n",
    "current_date = datetime.now()\n",
    "df['Age'] = ((current_date - df['BIRTHDATE']) / pd.Timedelta(days=365.25)).astype(int)\n",
    "\n",
    "# Display the DataFrame with the new 'Age' column\n",
    "print(df[['BIRTHDATE', 'Age']])\n",
    "\n",
    "# Now, read the modified DataFrame back from the CSV file\n",
    "df_modified = pd.read_csv('/Users/SarahA/synthea/final_data_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aedcb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
